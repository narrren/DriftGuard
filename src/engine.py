import os
import sys
import yaml
import argparse
import importlib

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from pydantic import BaseModel, Field, ValidationError
from typing import List, Dict, Any

# ==========================================
# üõ°Ô∏è Pydantic Schema Definitions
# ==========================================
class StageModel(BaseModel):
    name: str
    type: str
    enabled: bool = True
    severity: str = "warning"
    trigger_on: List[str]
    config: Dict[str, Any] = {}

class PolicyModel(BaseModel):
    stages: List[StageModel] = []
    cleanup: List[StageModel] = []

def load_policy(policy_path='policy.yaml'):
    if not os.path.exists(policy_path):
        policy_path = os.path.join(os.getcwd(), policy_path)
    if not os.path.exists(policy_path):
        print(f"‚ùå Policy file {policy_path} not found.")
        sys.exit(1)
    
    with open(policy_path, 'r') as f:
        raw_data = yaml.safe_load(f)
        
    try:
        print(f"üìú Validating Policy Schema ({policy_path})...")
        policy = PolicyModel(**raw_data)
        print("‚úÖ Policy Schema is Valid.")
        # Return as dict to preserve existing engine logic compatibility
        return policy.model_dump() 
    except ValidationError as e:
        print("\n‚õî Policy Configuration Error (Pydantic):")
        for err in e.errors():
            loc = " -> ".join([str(l) for l in err['loc']])
            print(f"   ‚ùå Field: {loc} | Error: {err['msg']}")
        sys.exit(1)

def execute_stage(stage, context, event_type):
    name = stage.get('name')
    if not stage.get('enabled', False):
        print(f"‚è≠Ô∏è  Stage '{name}' is disabled. Skipping.")
        return

    triggers = stage.get('trigger_on', [])
    if event_type not in triggers:
        return

    logger.info(f"Executing Stage: {name}", extra={"event": "stage_start", "stage": name, "type": stage.get('type')})
    
    status = True
    try:
        if name == 'ai_doc_check':
            from src.guards import ai_sync
            ai_sync.run(context, stage['config'])
            
        elif name == 'infrastructure_preview':
            # In a real engine, this might trigger terraform apply
            # For this MVP, we assume the GitHub Action step runs terraform 
            # OR we call a python wrapper. 
            # The prompt implies engine decides. Let's print info for the Action to use 
            # or if we had a python terraform wrapper, call it.
            # We will use the janitor script's 'provision' mode if it existed, 
            # but usually terraform is run directly by GH Actions.
            # We'll just validate config here.
            print(f"‚úÖ Infrastructure Policy Checked: TTL {stage['config']['ttl_hours']}h enforced.")

        elif name == 'cross_repo_safety':
            from src.guards import cross_repo
            cross_repo.run(context, stage['config'])

        elif name == 'janitor_cleanup':
             from src.guards import janitor
             janitor.scan_resources(stage['config'])

    except Exception as e:
        print(f"‚ùå Stage '{name}' failed: {e}")
        status = False
        import traceback
        traceback.print_exc()

    if not status:
        if stage.get('severity') == 'block':
            print(f"‚õî Blocking Merge due to failure in '{name}'.")
            sys.exit(1)
        else:
            print(f"‚ö†Ô∏è  Warning in '{name}', but severity is not block.")

import logging
from pythonjsonlogger import jsonlogger

# ==========================================
# üìä Observability Setup (JSON API)
# ==========================================
logger = logging.getLogger()
# Console Handler
logHandler = logging.StreamHandler()
formatter = jsonlogger.JsonFormatter('%(asctime)s %(levelname)s %(message)s')
logHandler.setFormatter(formatter)
logger.addHandler(logHandler)

# File Handler (for Artifact Upload)
fileHandler = logging.FileHandler('driftguard_engine.json.log')
fileHandler.setFormatter(formatter)
logger.addHandler(fileHandler)

logger.setLevel(logging.INFO)

def main():
    parser = argparse.ArgumentParser(description="DriftGuard Policy Engine")
    parser.add_argument('--event', type=str, required=True, help="GitHub Event Name")
    parser.add_argument('--action', type=str, required=True, help="Event Action")
    args = parser.parse_args()

    # Log Initialization Event
    logger.info("DriftGuard Engine Initializing", extra={
        "event": "engine_start", 
        "trigger": args.event, 
        "action": args.action,
        "repo": os.environ.get('GITHUB_REPOSITORY', 'unknown')
    })

    # Load Context
    context = {
        'pr_number': os.environ.get('PR_NUMBER'),
        'repo_name': os.environ.get('GITHUB_REPOSITORY'),
        'token': os.environ.get('GITHUB_TOKEN'),
        'gemini_key': os.environ.get('GEMINI_API_KEY'),
        'aws_region': os.environ.get('AWS_REGION', 'us-east-1'),
        'db_url': os.environ.get('DATABASE_URL'), # New Requirement: Needs to be in README!
        'secret_sauce': os.environ.get('SECRET_SAUCE') # Test Var for AI Fallback
    }

    policy = load_policy()
    
    # Determine which section of policy to run
    if args.action == 'closed':
        stages = policy.get('cleanup', [])
    else:
        stages = policy.get('stages', [])

    for stage in stages:
        execute_stage(stage, context, args.action)

if __name__ == "__main__":
    main()
